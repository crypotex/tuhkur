{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook describes a two-step process to classify comment offensivity. The solution seeks to solve Kaggle competition https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.\n",
    "\n",
    "The hypothesis is that two-step classification gives better results, because the predictive power of offence vs not offence is better when we pool offences in the first step. The problem is that offending comments only make up 10% of all of the comments, so to classify each offence class separately from the beginning would potentially cause smaller offence classes to be underclassified - to solve this problem, we propose two-step classification process.\n",
    "\n",
    "The first step is to train a binary classifier to identify if the comment is offensive or not. For this all the samples that have at least one offence category marked as 1 will be labelled as 1, others as 0. This step has two versions:\n",
    "\n",
    "Version 1 where model is trained on the \"as is\" data.\n",
    "\n",
    "Version 2 where offence class comments are over-sampled to have roughly equal representation to the non-offence class.\n",
    "\n",
    "The second step will be trained purely on offence data and will be used to distinguish between offences (score offences). The step will have two separate versions:\n",
    "\n",
    "Version 1 where model is trained on the \"as is\" offence data.\n",
    "\n",
    "Version 2 where smaller offence class comments are over-sampled to have roughly equal representation to the large offence classes.\n",
    "\n",
    "The additional property of this two-step classification is that second step serves also as a quality check for the first step - when the probability score for each of the offence types is eally low, then probably there has been a mistake in the first step and we can discard the comment as non-offensive.\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in and exploring the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                        22256635\n",
       "comment_text     Nonsense?  kiss off, geek. what I said is true...\n",
       "toxic                                                            1\n",
       "severe_toxic                                                     0\n",
       "obscene                                                          0\n",
       "threat                                                           0\n",
       "insult                                                           0\n",
       "identity_hate                                                    0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95851, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying offence vs accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a binary label column to indicate if offence or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['binary_label'] = Series(np.zeros(len(data['id'])), index=data.index)\n",
    "data.loc[data.iloc[:,1:].sum(axis=1) >= 1,'binary_label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of offending comments is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1021376928774943"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['binary_label']/len(data['binary_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train the classifier to identify if comment is offensive or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previously mentioned oversampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying offence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "offence_data = data[data.iloc[:,1:].sum(axis=1) >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier on the \"as is\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train with the previously mentioned oversampling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas and code testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(u'This is a sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
